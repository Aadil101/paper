@inbook{Fellbaum:2005,
    author  = {Christiane Fellbaum},
    title   = {Encyclopedia of Language and Linguistics, Second Edition},
    year    = "2005",
    chapter = {WordNet and wordnets},
    publisher = {Oxford: Elsevier}
}

@inproceedings{pennington2014glove,
  author = {Jeffrey Pennington and Richard Socher and Christopher D. Manning},
  booktitle = {Empirical Methods in Natural Language Processing (EMNLP)},
  title = {GloVe: Global Vectors for Word Representation},
  year = {2014},
  pages = {1532--1543},
  url = {http://www.aclweb.org/anthology/D14-1162},
}

@inproceedings{Peters:2018,
  author={Peters, Matthew E. and  Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
  title={Deep contextualized word representations},
  booktitle={Proc. of NAACL},
  year={2018}
}

@InProceedings{conneau-EtAl:2017:EMNLP2017,
  author    = {Conneau, Alexis  and  Kiela, Douwe  and  Schwenk, Holger  and  Barrault, Lo\"{i}c  and  Bordes, Antoine},
  title     = {Supervised Learning of Universal Sentence Representations from Natural Language Inference Data},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  month     = {September},
  year      = {2017},
  address   = {Copenhagen, Denmark},
  publisher = {Association for Computational Linguistics},
  pages     = {670--680},
  url       = {https://www.aclweb.org/anthology/D17-1070}
}

@article{gooding_kochmar_2018, 
  title     = {CAMB at CWI Shared Task 2018: Complex Word Identification with Ensemble-Based Voting}, 
  DOI       = {10.18653/v1/w18-0520}, 
  journal   = {Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications}, 
  author    = {Gooding, Sian and Kochmar, Ekaterina}, 
  year      = {2018}
}

@misc{phrasefinder,
  author       = {Martin Trenkmann},
  title        = {{PhraseFinder} -- Search millions of books for language use},
  howpublished = {\url{https://phrasefinder.io}},
  note         = {Accessed: 2021-02-08}
}

@INPROCEEDINGS{Loper02nltk:the,
    author = {Edward Loper and Steven Bird},
    title = {NLTK: The Natural Language Toolkit},
    booktitle = {In Proceedings of the ACL Workshop on Effective Tools and Methodologies for Teaching Natural Language Processing and Computational Linguistics. Philadelphia: Association for Computational Linguistics},
    year = {2002}
}

@InProceedings{manning-EtAl:2014:P14-5,
  author    = {Manning, Christopher D. and  Surdeanu, Mihai  and  Bauer, John  and  Finkel, Jenny  and  Bethard, Steven J. and  McClosky, David},
  title     = {The {Stanford} {CoreNLP} Natural Language Processing Toolkit},
  booktitle = {Association for Computational Linguistics (ACL) System Demonstrations},
  year      = {2014},
  pages     = {55--60},
  url       = {http://www.aclweb.org/anthology/P/P14/P14-5010}
}

@book{gunning1952technique,
  title={The Technique of Clear Writing},
  author={Gunning, R.},
  lccn={51013126},
  url={https://books.google.com/books?id=ofI0AAAAMAAJ},
  year={1952},
  publisher={McGraw-Hill}
}

@article{Tibshirani.x,
author = {Tibshirani, Robert},
title = {Regression Shrinkage and Selection Via the Lasso},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {58},
number = {1},
pages = {267-288},
keywords = {quadratic programming, regression, shrinkage, subset selection},
doi = {https://doi.org/10.1111/j.2517-6161.1996.tb02080.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1996.tb02080.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1996.tb02080.x},
abstract = {SUMMARY We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
year = {1996}
}

@article{10.2307/3647580,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/3647580},
 abstract = {We propose the elastic net, a new regularization and variable selection method. Real world data and a simulation study show that the elastic net often outperforms the lasso, while enjoying a similar sparsity of representation. In addition, the elastic net encourages a grouping effect, where strongly correlated predictors tend to be in or out of the model together. The elastic net is particularly useful when the number of predictors (p) is much bigger than the number of observations (n). By contrast, the lasso is not a very satisfactory variable selection method in the p ≫ n case. An algorithm called LARS-EN is proposed for computing elastic net regularization paths efficiently, much like algorithm LARS does for the lasso.},
 author = {Hui Zou and Trevor Hastie},
 journal = {Journal of the Royal Statistical Society. Series B (Statistical Methodology)},
 number = {2},
 pages = {301--320},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Regularization and Variable Selection via the Elastic Net},
 volume = {67},
 year = {2005}
}

@inproceedings{liuetal2019multitask,
    title = "Multi-Task Deep Neural Networks for Natural Language Understanding",
    author = "Liu, Xiaodong  and
      He, Pengcheng  and
      Chen, Weizhu  and
      Gao, Jianfeng",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-1441",
    doi = "10.18653/v1/P19-1441",
    pages = "4487--4496",
    abstract = "In this paper, we present a Multi-Task Deep Neural Network (MT-DNN) for learning representations across multiple natural language understanding (NLU) tasks. MT-DNN not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. MT-DNN extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as BERT (Devlin et al., 2018). MT-DNN obtains new state-of-the-art results on ten NLU tasks, including SNLI, SciTail, and eight out of nine GLUE tasks, pushing the GLUE benchmark to 82.7{\%} (2.2{\%} absolute improvement) as of February 25, 2019 on the latest GLUE test set. We also demonstrate using the SNLI and SciTail datasets that the representations learned by MT-DNN allow domain adaptation with substantially fewer in-domain labels than the pre-trained BERT representations. Our code and pre-trained models will be made publicly available.",
}

@article{DBLP:journals/corr/abs-1810-04805,
  author    = {Jacob Devlin and
               Ming{-}Wei Chang and
               Kenton Lee and
               Kristina Toutanova},
  title     = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
               Understanding},
  journal   = {CoRR},
  volume    = {abs/1810.04805},
  year      = {2018},
  url       = {http://arxiv.org/abs/1810.04805},
  archivePrefix = {arXiv},
  eprint    = {1810.04805},
  timestamp = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hartmanndossantos2018nilc,
    title = "{NILC} at {CWI} 2018: Exploring Feature Engineering and Feature Learning",
    author = "Hartmann, Nathan  and
      dos Santos, Leandro Borges",
    booktitle = "Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-0540",
    doi = "10.18653/v1/W18-0540",
    pages = "335--340",
    abstract = "This paper describes the results of NILC team at CWI 2018. We developed solutions following three approaches: (i) a feature engineering method using lexical, n-gram and psycholinguistic features, (ii) a shallow neural network method using only word embeddings, and (iii) a Long Short-Term Memory (LSTM) language model, which is pre-trained on a large text corpus to produce a contextualized word vector. The feature engineering method obtained our best results for the classification task and the LSTM model achieved the best results for the probabilistic classification task. Our results show that deep neural networks are able to perform as well as traditional machine learning methods using manually engineered features for the task of complex word identification in English.",
}

@article{DBLP:journals/corr/VaswaniSPUJGKP17,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  archivePrefix = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{wolf_etal_2020_transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article{DBLP:journals/corr/abs-1906-04341,
  author    = {Kevin Clark and
               Urvashi Khandelwal and
               Omer Levy and
               Christopher D. Manning},
  title     = {What Does {BERT} Look At? An Analysis of BERT's Attention},
  journal   = {CoRR},
  volume    = {abs/1906.04341},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.04341},
  archivePrefix = {arXiv},
  eprint    = {1906.04341},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-04341.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/ChenG16,
  author    = {Tianqi Chen and
               Carlos Guestrin},
  title     = {XGBoost: {A} Scalable Tree Boosting System},
  journal   = {CoRR},
  volume    = {abs/1603.02754},
  year      = {2016},
  url       = {http://arxiv.org/abs/1603.02754},
  archivePrefix = {arXiv},
  eprint    = {1603.02754},
  timestamp = {Mon, 13 Aug 2018 16:47:00 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChenG16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{190509418,
  author    = {Elena Voita and
               David Talbot and
               Fedor Moiseev and
               Rico Sennrich and
               Ivan Titov},
  title     = {Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy
               Lifting, the Rest Can Be Pruned},
  journal   = {CoRR},
  volume    = {abs/1905.09418},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.09418},
  archivePrefix = {arXiv},
  eprint    = {1905.09418},
  timestamp = {Wed, 29 May 2019 11:27:50 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-09418.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{190604341,
  author    = {Kevin Clark and
               Urvashi Khandelwal and
               Omer Levy and
               Christopher D. Manning},
  title     = {What Does {BERT} Look At? An Analysis of BERT's Attention},
  journal   = {CoRR},
  volume    = {abs/1906.04341},
  year      = {2019},
  url       = {http://arxiv.org/abs/1906.04341},
  archivePrefix = {arXiv},
  eprint    = {1906.04341},
  timestamp = {Fri, 14 Jun 2019 09:38:24 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1906-04341.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{1905-10650,
  author    = {Paul Michel and
               Omer Levy and
               Graham Neubig},
  title     = {Are Sixteen Heads Really Better than One?},
  journal   = {CoRR},
  volume    = {abs/1905.10650},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.10650},
  archivePrefix = {arXiv},
  eprint    = {1905.10650},
  timestamp = {Mon, 03 Jun 2019 13:42:33 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1905-10650.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{gigaword, 
  author = {Parker, Robert and others},
  year = {2011},
  note = {English Gigaword Fifth Edition LDC2011T07. Web Download. Philadelphia: Linguistic Data Consortium, 2011.}
}

@misc{BNC, 
  author = {{The British National Corpus}},
  year = {2007},
  note = {URL: \url{http://www.natcorp.ox.ac.uk/}},
}

@article{Brysbaert2009MovingBK,
  title = {Moving beyond Kučera and Francis: A critical evaluation of current word frequency norms and the introduction of a new and improved word frequency measure for American English},
  author = {M. Brysbaert and B. New},
  journal = {Behavior Research Methods},
  year = {2009},
  volume = {41},
  pages = {977-990}
}

@misc{shardlow2020complex,
      title={CompLex: A New Corpus for Lexical Complexity Prediction from Likert Scale Data}, 
      author={Matthew Shardlow and Michael Cooper and Marcos Zampieri},
      year={2020},
      eprint={2003.07008},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{raynerd86,
  added-at = {2011-05-09T23:10:52.000+0200},
  author = {Rayner, K. and Duffy, S. A.},
  biburl = {https://www.bibsonomy.org/bibtex/248ebee36b8ec804c975084edf62a8a1f/josephausterwei},
  interhash = {0ea26203b47764367986d7bf3f28e5b5},
  intrahash = {48ebee36b8ec804c975084edf62a8a1f},
  journal = {Memory \& Cognition},
  keywords = {imported},
  pages = {191-201},
  timestamp = {2011-05-10T10:42:42.000+0200},
  title = {Lexical complexity and fixation times in reading:
  Effects of word frequency, verb complexity, and lexical ambiguity},
  volume = "14",
  year = "1986"
}

@inproceedings{shardlow2014open,
    title = "Out in the Open: Finding and Categorising Errors in the Lexical Simplification Pipeline",
    author = "Shardlow, Matthew",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/479_Paper.pdf",
    pages = "1583--1590",
    abstract = "Lexical simplification is the task of automatically reducing the complexity of a text by identifying difficult words and replacing them with simpler alternatives. Whilst this is a valuable application of natural language generation, rudimentary lexical simplification systems suffer from a high error rate which often results in nonsensical, non-simple text. This paper seeks to characterise and quantify the errors which occur in a typical baseline lexical simplification system. We expose 6 distinct categories of error and propose a classification scheme for these. We also quantify these errors for a moderate size corpus, showing the magnitude of each error type. We find that for 183 identified simplification instances, only 19 (10.38{\%}) result in a valid simplification, with the rest causing errors of varying gravity.",
}

@misc{devlintait,
  author = {Siobhan Devlin and John Tait},
  year = {1998},
  notes = {Siobhan Devlin and John Tait. 1998. The use of a psy- cholinguistic database in the simplification of text for aphasic readers. Linguistic Databases, pages 161–173.}
}

@InProceedings{10.1007/11573067_19,
  author="Zeng, Qing
  and Kim, Eunjung
  and Crowell, Jon
  and Tse, Tony",
  editor="Oliveira, Jos{\'e} Lu{\'i}s
  and Maojo, V{\'i}ctor
  and Mart{\'i}n-S{\'a}nchez, Fernando
  and Pereira, Ant{\'o}nio Sousa",
  title="A Text Corpora-Based Estimation of the Familiarity of Health Terminology",
  booktitle="Biological and Medical Data Analysis",
  year="2005",
  publisher="Springer Berlin Heidelberg",
  address="Berlin, Heidelberg",
  pages="184--192",
  abstract="In a pilot effort to improve health communication we created a method for measuring the familiarity of various medical terms. To obtain term familiarity data, we recruited 21 volunteers who agreed to take medical terminology quizzes containing 68 terms. We then created predictive models for familiarity based on term occurrence in text corpora and reader's demographics. Although the sample size was small, our preliminary results indicate that predicting the familiarity of medical terms based on an analysis of the frequency in text corpora is feasible. Further, individualized familiarity assessment is feasible when demographic features are included as predictors.",
  isbn="978-3-540-31658-9"
}

@InProceedings{paetzoldspecia:2016:SemEval1,
  author    = {Paetzold, Gustavo  and  Specia, Lucia},
  title     = {SemEval 2016 Task 11: Complex Word Identification},
  booktitle = {Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016)},
  year      = {2016}
}

@InProceedings{stajner-EtAl:2018:BEA,
  author    = {\v{S}tajner, Sanja and Biemann, Chris and Malmasi, Shervin and Paetzold, Gustavo and Specia, Lucia and Tack, Ana\"{i}s and Yimam, Seid Muhie and Zampieri, Marcos},
  title     = {A Report on the Complex Word Identification Shared Task 2018},
  booktitle = {Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications},
  year      = {2018}
}

@article{10.2307/40011226,
 ISSN = {00224103},
 URL = {http://www.jstor.org/stable/40011226},
 author = {G. Harry McLaughlin},
 journal = {Journal of Reading},
 number = {8},
 pages = {639--646},
 publisher = {[Wiley, International Reading Association]},
 title = {SMOG Grading-a New Readability Formula},
 volume = {12},
 year = {1969}
}

@article{10.2307/1473169,
 ISSN = {15554023},
 URL = {http://www.jstor.org/stable/1473169},
 author = {Edgar Dale and Jeanne S. Chall},
 journal = {Educational Research Bulletin},
 number = {1},
 pages = {11--28},
 publis` = {Taylor & Francis, Ltd.},
 title = {A Formula for Predicting Readability},
 volume = {27},
 year = {1948}
}

@inproceedings{shardlow2013comparison,
    title = "A Comparison of Techniques to Automatically Identify Complex Words.",
    author = "Shardlow, Matthew",
    booktitle = "51st Annual Meeting of the Association for Computational Linguistics Proceedings of the Student Research Workshop",
    month = aug,
    year = "2013",
    address = "Sofia, Bulgaria",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P13-3015",
    pages = "103--109",
}

@InProceedings{zampieriEtAl:2017:NLPTEA,
  author    = {Zampieri, Marcos  and  Malmasi, Shervin  and  Paetzold, Gustavo  and Specia, Lucia},
  title     = {Complex Word Identification: Challenges in Data Annotation and System Performance},
  booktitle = {Proceedings of the 4th Workshop on Natural Language Processing Techniques for Educational Applications (NLPTEA 2017)},
  year      = {2017}
}

@inproceedings{paetzoldspecia2016sv000gg,
    title = "{SV}000gg at {S}em{E}val-2016 Task 11: Heavy Gauge Complex Word Identification with System Voting",
    author = "Paetzold, Gustavo  and
      Specia, Lucia",
    booktitle = "Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S16-1149",
    doi = "10.18653/v1/S16-1149",
    pages = "969--974",
}

@inproceedings{ronzanoetal2016taln,
    title = "{TALN} at {S}em{E}val-2016 Task 11: Modelling Complex Words by Contextual, Lexical and Semantic Features",
    author = "Ronzano, Francesco  and
      Abura{'}ed, Ahmed  and
      Espinosa-Anke, Luis  and
      Saggion, Horacio",
    booktitle = "Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S16-1157",
    doi = "10.18653/v1/S16-1157",
    pages = "1011--1016",
}

@inproceedings{mukherjeeetal2016ju,
    title = "{JU}{\_}{NLP} at {S}em{E}val-2016 Task 11: Identifying Complex Words in a Sentence",
    author = "Mukherjee, Niloy  and
      Patra, Braja Gopal  and
      Das, Dipankar  and
      Bandyopadhyay, Sivaji",
    booktitle = "Proceedings of the 10th International Workshop on Semantic Evaluation ({S}em{E}val-2016)",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S16-1152",
    doi = "10.18653/v1/S16-1152",
    pages = "986--990",
}

@inproceedings{dehertogtack2018deep,
    title = "Deep Learning Architecture for Complex Word Identification",
    author = {De Hertog, Dirk  and
      Tack, Ana{\"\i}s},
    booktitle = "Proceedings of the Thirteenth Workshop on Innovative Use of {NLP} for Building Educational Applications",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-0539",
    doi = "10.18653/v1/W18-0539",
    pages = "328--334",
    abstract = "We describe a system for the CWI-task that includes information on 5 aspects of the (complex) lexical item, namely distributional information of the item itself, morphological structure, psychological measures, corpus-counts and topical information. We constructed a deep learning architecture that combines those features and apply it to the probabilistic and binary classification task for all English sets and Spanish. We achieved reasonable performance on all sets with best performances seen on the probabilistic task, particularly on the English news set (MAE 0.054 and F1-score of 0.872). An analysis of the results shows that reasonable performance can be achieved with a single architecture without any domain-specific tweaking of the parameter settings and that distributional features capture almost all of the information also found in hand-crafted features.",
}

@InProceedings{pmlrv74branco17a, 
  title = {{SMOGN}: a Pre-processing Approach for Imbalanced Regression}, 
  author = {Paula Branco and Luís Torgo and Rita P. Ribeiro}, 
  booktitle = {Proceedings of the First International Workshop on Learning with Imbalanced Domains: Theory and Applications}, 
  pages = {36--50}, 
  year = {2017}, 
  editor = {Luís Torgo and Bartosz Krawczyk and Paula Branco and Nuno Moniz}, 
  volume = {74}, 
  series = {Proceedings of Machine Learning Research}, 
  address = {ECML-PKDD, Skopje, Macedonia}, 
  month = {22 Sep}, 
  publisher = {PMLR}, 
  pdf = {http://proceedings.mlr.press/v74/branco17a/branco17a.pdf}, 
  url = {http://proceedings.mlr.press/v74/branco17a.html}, 
  abstract = {The problem of imbalanced domains, framed within predictive tasks, is relevant in many practical applications. When dealing with imbalanced domains a performance degradation is usually observed on the most rare and relevant cases for the user. This problem has been thoroughly studied within a classification setting where the target variable is nominal. The exploration of this problem in other contexts is more recent within the research community. For regression tasks, where the target variable is continuous, only a few solutions exist. Pre-processing strategies are among the most successful proposals for tackling this problem. In this paper we propose a new pre-processing approach for dealing with imbalanced regression. Our algorithm, SMOGN, incorporates two existing proposals trying to solve problems detected in both of them. We show that SMOGN has advantages in comparison to other approaches. We also show that our method has a different impact on the learners used, displaying more advantages for Random Forest and Multivariate Adaptive Regression Splines learners.} 
}